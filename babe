#!/usr/bin/env python
# Copyright 2019 PhonePe Pvt. Ltd.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import argparse
import json
import requests
import os.path
import time
import getpass
import re
from tabulate import tabulate
from termcolor import colored
from requests.auth import HTTPBasicAuth
from requests.exceptions import ConnectionError
import tqdm
import warnings
import traceback
from datetime import datetime
import yaml
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart

# I personally don`t like doing this :)
warnings.filterwarnings("ignore")

marathon="localhost:8080"
waitTime=10
userAuth=False
httpBasicCreds = None
protocol = "http"
httpsVerify = True
defaultConfigPath="/etc/babe/config.yml"
babeConfig = None
disableEmail = False
requestsTimeout = 5
adminPort = 1
instancePort = 0

def readConfig(configPath):
    try:
        return yaml.safe_load(open(configPath))
    except Exception:
        print("Unable to load the configuration from path " + configPath)
        return None

def getEmailTo(babeConfig):
    if None == babeConfig:
        return None
    else:
        return babeConfig['default_receiver']

def getAppOwnerEmail(appDataJson):
    appOwnerEmail = None
    if 'app.owner.email' in appDataJson['labels']:
        appOwnerEmail = appDataJson['labels']['app.owner.email']
    return appOwnerEmail

def sendEmail(subject, content, to, cc):
    if disableEmail or None == babeConfig or None == to:
        print("Warning: Email notifications disabled")
        return
    server = smtplib.SMTP(babeConfig['smtp_server'], babeConfig['port'])
    try:
        msg = MIMEMultipart()
        msg['Subject'] = subject
        msg['From'] = babeConfig['sender_email']
        if not None == cc:
            msg['CC'] = cc
        if None == to:
            raise Exception('To param cannot be empty for email')
        msg['To'] = to
        messageBody = MIMEText(content, 'html')
        msg.attach(messageBody)
        server.sendmail(babeConfig['sender_email'], to, msg.as_string())
        if None == cc:
            print("An email has been sent to: " + to)
        else:
            print("An email has been sent to: " + to + ", cc: " + cc)
    except Exception as e:
        print("An error occurred while sending email to: " + to + ", cc: " + cc)
        print(e)
    finally:
        server.quit()

def get_leader_url(path):
    cur_url = protocol + "://" + marathon + "/v2/leader"
    l_res = requests.get(cur_url)
    if l_res.status_code == 200:
        l_data = l_res.json()
        return protocol + "://" + l_data['leader'] + path
    else:
        print("Returning seeded marathon endpoint since leader call gave status : " + l_res.status_code)
        return protocol + "://" + marathon + path

def url(path):
    return get_leader_url(path)

def endpoint_url(endpoint, path):
    return protocol + "://" + endpoint + path

def mesos_master_endpoint():
    return marathon.split(':')[0] + ':' + "5050"

def printApiError(r):
    if r.status_code == 401:
        print("Authentication error:: Check your username and password")
        return
    error=json.loads(r.text)
    try:
        if 'details' in error:
            print("Error: Marathon returned [" + str(r.status_code) + "] : " + error['message'] + ": " + error['details'])
        else:
            print("Error: Marathon returned [" + str(r.status_code) + "] : " + error['message'])
    except:
        print("Error: Marathon returned [" + str(r.status_code) + "] : " + r.text)

def printInfoTable(apps, aliveOnly=False, deadOnly=False, searchTerm=None):
    rows=[]
    for app in apps:
        if True == aliveOnly and 0 == app['tasksHealthy']:
            continue
        if True == deadOnly and 0 < app['tasksHealthy']:
            continue
        row=[]
        row.append(app['id'])
        row.append(app['cpus'])
        row.append(app['mem'])
        #row.append(app['tasksHealthy'])
        if not 'taskStats' in app or not 'totalSummary' in app['taskStats']:
            row.append(0)
            row.append(0)
            row.append(0)
            row.append(0)
            row.append(colored("DOWN", 'red'))
        else:
            taskStats=app['taskStats']['totalSummary']['stats']['counts']
            row.append(taskStats['healthy'])
            row.append(taskStats['unhealthy'])
            row.append(taskStats['running'])
            row.append(taskStats['staged'])
            row.append(colored("UP", 'green'))
        if searchTerm:
            if searchTerm in app['id']:
                rows.append(row)
        else:
            rows.append(row)
    print(tabulate(rows, headers=["App", "CPU", "Ram (MB)", "# Healthy", "# Unhealthy", "# Running", "# Deploying", "Status"], tablefmt='fancy_grid'))

def apps(aliveOnly, deadOnly, searchTerm=None):
    params = {'embed' : 'apps.taskStats'}
    r = requests.get(url("/v2/apps"), params=params, auth=httpBasicCreds, verify=httpsVerify)
    if 200 != r.status_code:
        printApiError(r)
        return
    apps = r.json()['apps']
    apps.sort(key=lambda x: x['id'])
    printInfoTable(apps, aliveOnly=aliveOnly, deadOnly=deadOnly, searchTerm=searchTerm)

def listCommand(listArgParser):
    if listArgParser.up and listArgParser.down:
        print("Both 'up' and 'down' together doesn't make sense. Are you testing me? Don't...")
        return
    apps(listArgParser.up, listArgParser.down, searchTerm=listArgParser.search)

def deployCommand(deployOptionsParser):
    configFile=deployOptionsParser.config
    if not os.path.isfile(configFile):
        print("Error: Deployment descriptor file " + configFile + " does not exist")
        return
    with open(configFile, 'r') as myfile:
        data = myfile.read()
    r = requests.post(url("/v2/apps"), data = data, headers = {'content-type': 'application/json'}, auth=httpBasicCreds, verify=httpsVerify)
    if r.status_code == 201:
        print("App deployment request accepted. Use list command to check")

        jsonData = json.loads(data)
        appOwnerEmail = getAppOwnerEmail(jsonData)
        subject = "[Babe Alert] Deploying " + str(jsonData['id'])
        content = "App: " + str(jsonData['id']) + "<br>" + "Endpoint: " + str(marathon) + "<br>" + "User: " + getpass.getuser()
        if None == appOwnerEmail:
            content = content + "<br> Warning: No app owner registered for "+ str(jsonData['id'])
        sendEmail(subject, content, getEmailTo(babeConfig), appOwnerEmail)

    elif r.status_code == 409:
        print("Error: App already exists")
    else:
        printApiError(r)

def loadInstance(instance, rows):
    row = []
    row.append(instance['id'])
    row.append(instance['host'])
    row.append(', '.join([str(x) for x in instance['ports']]))
    row.append(instance['startedAt'])
    if 'healthCheckResults' in instance:
        if instance['healthCheckResults'][0]['alive'] == True:
            row.append(colored('HEALTHY', 'green'))
        else:
            row.append(colored('UNHEALTHY', 'red'))
    else:
        row.append(colored('STAGING', 'yellow'))
    rows.append(row)

def isInstanceHealthy(instance):
    return 'healthCheckResults' in instance and len(instance['healthCheckResults']) > 0 and instance['healthCheckResults'][0]['alive'] == True

def adminEndpoint(instance):
    if 'ports' in instance and len(instance['ports']) >= 2:
        return "http://" + instance['host'] + ":" + str(instance['ports'][adminPort])
    return None

def getRangerOorUrl(instance, isNodeApp=False):
    if not isNodeApp:
        instanceAdminEndpoint = adminEndpoint(instance)
        if instanceAdminEndpoint is not None:
            return instanceAdminEndpoint + "/tasks/ranger-oor"
    elif isNodeApp and 'ports' in instance and len(instance['ports']) >= 1:
        return "http://" + instance['host'] + ":" + str(instance['ports'][instancePort]) + "/internal/oor"
    return None

def getAppInfo(appName):
    params = {'embed' : ['apps.taskStats', 'apps.deployments']}
    r = requests.get(url("/v2/apps/" + appName), params=params, auth=httpBasicCreds, verify=httpsVerify)
    if 200 != r.status_code:
        printApiError(r)
        return None
    return r

def scale(appName, scale, force=False):
    r = requests.put(url("/v2/apps/"+appName), data= json.dumps({'instances' : scale}), headers = {'content-type': 'application/json'}, auth=httpBasicCreds, verify=httpsVerify)
    if 200 == r.status_code:
        print("App " + appName + " scaled to " + str(scale))
    else:
        printApiError(r)

def killInstance(appName, instance, grace, rangerOOR, lbOOR, scale, isNodeApp=False, fabric=False):
    endpoint = adminEndpoint(instance)
    if not isNodeApp and None == endpoint:
        print("No admin port info in instance: " + instance['id'])
        return

    if fabric:
        closeProcessorUrl = endpoint + "/close-processors"
        print("Calling " + closeProcessorUrl)
        try:
            closeProcessorResponse = requests.put(closeProcessorUrl, auth=httpBasicCreds, verify=httpsVerify, timeout=requestsTimeout)
            if 200 == closeProcessorResponse.status_code:
                print("Closed processor")
            elif 404 == closeProcessorResponse.status_code:
                print("Close processor api returned 404")
            else:
                print("Close processor api returned: [" + str(closeProcessorResponse.status_code) + "] " + closeProcessorResponse.text)
                return
        except ConnectionError:
            print("Skipping connection error - exposed admin port may be invalid ?!")
            pass

    if rangerOOR:
        rangerOorUrl = getRangerOorUrl(instance, isNodeApp)
        print("Calling " + rangerOorUrl)
        try:
            oorResponse=requests.post(rangerOorUrl, auth=httpBasicCreds, verify=httpsVerify, timeout=requestsTimeout)
            if 200 == oorResponse.status_code or 201 == oorResponse.status_code:
                print("Took node oor on ranger")
            elif 404 == oorResponse.status_code:
                print("Ranger OOR api returned 404")
            else:
                print("Ranger OOR api returned: [" + str(oorResponse.status_code) + "] " + oorResponse.text)
                return
        except ConnectionError:
            print("Skipping connection error - exposed admin port may be invalid ?!")
            pass

    if not isNodeApp and lbOOR:
        loadbalancer_oor_url = endpoint + "/tasks/OorTask"
        print("Calling " + loadbalancer_oor_url)
        try:
            oorResponse = requests.post(loadbalancer_oor_url, auth=httpBasicCreds, verify=httpsVerify, timeout=requestsTimeout)
            if 200 == oorResponse.status_code or 201 == oorResponse.status_code:
                print("Node is oor on loadbalancer")
            elif 404 == oorResponse.status_code:
                print("Ranger OOR api returned 404")
            else:
                print("Loadbalancer OOR api returned: [" + str(
                    oorResponse.status_code) + "] !! If this is being fronted by loadbalancer, inflight calls will fail!")
        except ConnectionError:
            print("Skipping connection error - exposed admin port may be invalid ?!")
            pass

    print("Waiting for grace period: " + str(grace) + " Second(s)")
    time.sleep(grace)
    params={'scale' : scale}
    killResponse=requests.delete(url("/v2/apps/" + appName + "/tasks/" + instance['id']), params=params, auth=httpBasicCreds, verify=httpsVerify)
    if 200 == killResponse.status_code:
        print("Killed " + instance['id'])
    else:
        print("Kill api returned: [" + str(killResponse.status_code) + "] " + killResponse.text)

def suspendParallel(appName, instances, grace, rangerOOR, lbOOR, parallelism, scale, isNodeApp=False, fabric=False):
    for i in tqdm.tqdm(range(0,len(instances), parallelism)):
        for instance in instances[i:i+parallelism]:
            endpoint = adminEndpoint(instance)
            if not isNodeApp and None == endpoint:
                print("No admin port info in instance: " + instance['id'])
                return

            if fabric:
                closeProcessorUrl = endpoint + "/close-processors"
                print("Calling " + closeProcessorUrl)

                closeProcessorResponse = requests.put(closeProcessorUrl, auth=httpBasicCreds, verify=httpsVerify)
                if 200 == closeProcessorResponse.status_code:
                    print("Closed processor")
                else:
                    print("Close processor api returned: [" + str(closeProcessorResponse.status_code) + "] " + closeProcessorResponse.text)
                    return
            if rangerOOR:
                rangerOorUrl = getRangerOorUrl(instance, isNodeApp)
                print("Calling " + rangerOorUrl)
                oorResponse=requests.post(rangerOorUrl, auth=httpBasicCreds, verify=httpsVerify)
                if 200 == oorResponse.status_code or 201 == oorResponse.status_code:
                    print("Took node oor on ranger")
                else:
                    print("OOR api returned: [" + str(oorResponse.status_code) + "] " + oorResponse.text)
                    return
            if not isNodeApp and lbOOR:
                loadbalancer_oor_url = endpoint + "/tasks/OorTask"
                print("Calling " + loadbalancer_oor_url)
                oorResponse = requests.post(loadbalancer_oor_url, auth=httpBasicCreds, verify=httpsVerify)
                if 200 == oorResponse.status_code or 201 == oorResponse.status_code:
                    print("Node is oor on loadbalancer")
                else:
                    print("Loadbalancer oor api returned: [" + str(oorResponse.status_code) + "] !! If this is being fronted by loadbalancer, inflight calls will fail!")

        print("Waiting for grace period: " + str(grace) + " Second(s)")
        time.sleep(grace)
        deleteBatchInstance(appName, instances[i:i+parallelism], scale)

def deleteBatchInstance(appName, instances, scale):
    ids = []
    for instance in instances:
        ids.append(instance['id'])
    params={'scale' : scale}
    killResponse=requests.post(url("/v2/tasks/delete"), data= json.dumps({'ids' : ids}), params=params, auth=httpBasicCreds, verify=httpsVerify)
    if 200 == killResponse.status_code:
        print("Killed " + str(ids))
    else:
        print("Kill api returned: [" + str(killResponse.status_code) + "] " + killResponse.text)
        print("Retrying after 2 seconds")
        time.sleep(2)
        deleteBatchInstance(appName, instances, scale)


def destroyApp(appName, force=False):
    if not force:
        prompt_response = raw_input("Do you really want to destroy the app {0} [y/n]? ".format(appName))
    if force or prompt_response == 'y':
        r = requests.delete(url("/v2/apps/" + appName), auth=httpBasicCreds, verify=httpsVerify)
        if 200 == r.status_code:
            print("App " + appName + " destroyed")
        else:
            printApiError(r)
    else:
        print("Not destroying app {0}".format(appName))

def destroyCommand(destroyAppOptionsParser):
    appName = destroyAppOptionsParser.app
    r = getAppInfo(appName)
    if None == r:
        print("Error: No such app:" + appName)
        return
    data=r.json()
    app=data['app']
    appOwnerEmail = getAppOwnerEmail(app)
    subject = "[Babe Alert] Destroying " + str(app['id'])
    content = "App: " + str(app['id']) + "<br>" + "Endpoint: " + str(marathon) + "<br>" + "User: " + getpass.getuser()
    if None == appOwnerEmail:
        content = content + "<br> Warning: No app owner registered for "+ str(app['id'])
    sendEmail(subject, content, getEmailTo(babeConfig), appOwnerEmail)

    destroyApp(appName)

def getMesosSlaveId(mesosMasterEndpoint, hostname):
    r = requests.get(endpoint_url(mesosMasterEndpoint, '/slaves'), auth=httpBasicCreds, verify=httpsVerify)
    if 200 == r.status_code:
        slaves = [slave['id'] for slave in r.json()['slaves'] if slave['hostname'] == hostname and slave['active'] == True]
        if not slaves:
            print("No matching active mesos slave with hostname {0}".format(hostname))
            return
        elif len(slaves) > 1:
            print("Multiple active mesos slaves with hostname {0}".format(hostname))
            return
        else:
            return slaves[0]

def getIsNodeAppFromApp(app):
    if 'env' in app:
        env = app['env']
        return (type(env) is dict and 'NODE_ENV' in env)
    return False

def getInstanceInfo(appName):
    r = getAppInfo(appName)
    if None == r:
        print("No app: " + appName)
        return
    data=r.json()
    app=data['app']
    instances = app['tasks']
    isNodeApp = getIsNodeAppFromApp(app)
    return {'instanceList': instances, 'isNodeApp': isNodeApp}

def getTaskInstance(task, filter):
    instanceInfo = getInstanceInfo(task['appId'])
    if filter(instanceInfo['instanceList']):
        return {'appName': task['appId'], 'taskId': task['id'], 'isNodeApp': instanceInfo['isNodeApp'], 'instance': task}

def decommission(mesosMasterEndpoint, hostname):
    if not mesosMasterEndpoint:
        mesosMasterEndpoint = mesos_master_endpoint()
    slaveId = getMesosSlaveId(mesosMasterEndpoint, hostname)
    if not slaveId:
        print("Cannot resolve slaveId for hostname {0}".format(hostname))
        return
    prompt_response = raw_input("Do you really want to decommission node with hostname = {0}, slaveId = {1} [y/n]? ".format(hostname, slaveId))
    if prompt_response != 'y':
        print("Not going to decommission")
        return
    r = requests.get(url("/v2/tasks"), auth=httpBasicCreds, verify=httpsVerify)
    if 200 != r.status_code:
        print("Tasks API errored out - returned: [" + str(r.status_code) + "] " + r.text)
        return
    print("Fetching list of tasks that need to be killed....")
    tasks_on_slave = sorted([task for task in r.json()['tasks'] if task['slaveId'] == slaveId])
    candidate_tasks = sorted([getTaskInstance(task, lambda l: len(l) > 1) for task in tasks_on_slave])
    skipped_tasks = [getTaskInstance(task, lambda l: len(l) == 1) for task in tasks_on_slave if task not in candidate_tasks]
    candidate_tasks = [task for task in candidate_tasks if task is not None]
    skipped_tasks = [task for task in skipped_tasks if task is not None]
    prompt_response = raw_input(
        "Do you want to ignore single instance apps on node with hostname = {0}, slaveId = {1} [y/n]? ".format(hostname, slaveId))
    if prompt_response == 'y':
        print("Single instance applications:")
        print (skipped_tasks)
        re_added_apps = []
        prompt_response = raw_input("Ignore app list/pattern (Separated by comma):")
        if ',' in prompt_response:
            ignore_app_list = prompt_response.split(",")
            for i_app in ignore_app_list:
                for s_task in skipped_tasks:
                    if s_task['appName'] == i_app or re.match(i_app, s_task['appName']) is not None:
                        candidate_tasks.append(s_task)
                        re_added_apps.append(s_task)
        else:
            for s_task in skipped_tasks:
                if s_task['appName'] == prompt_response or re.match(prompt_response, s_task['appName']) is not None:
                    candidate_tasks.append(s_task)
                    re_added_apps.append(s_task)
        candidate_tasks = sorted([task for task in candidate_tasks if task is not None])
        skipped_tasks = sorted([task for task in candidate_tasks if task['appName'] not in re_added_apps])

    failures = []
    apps_to_scale = dict()
    for task in candidate_tasks:
        apps_to_scale[task['appName']] = len(getInstanceInfo(task['appName'])['instanceList'])
    if skipped_tasks:
        print("Skipping suspend of following apps because they are running with only one instance \n{0}"
            .format("\n".join(set([task['appName'] for task in skipped_tasks]))))
        print("Cannot proceed further unless these apps are scaled up.... Exiting")
        exit(1)
    for task in tqdm.tqdm(candidate_tasks):
        print("Killing app = {0}, instance = {1}".format(task['appName'], task['taskId']))
        try:
            killInstance(appName=task['appName'], instance=task['instance'], grace=30, rangerOOR=True, lbOOR=True, scale=True, isNodeApp=task['isNodeApp'])
        except KeyboardInterrupt:
            print("Received <CTRL-C> stopping everything")
            exit(1)
        except:
            print("Failed to kill app = {0}, instance = {1}".format(task['appName'], task['taskId']))
            print(traceback.format_exc())
            exit(1)
            #failures.append({'appName': task['appName'], 'taskId': task['taskId']})
    if failures:
        print("Failed to properly suspend the following tasks \n{0}".format("\n".join([task['taskId'] for task in failures])))
    else:
        all_slaves_killed = raw_input("Is all slaves killed completely? Please check and respond. [y/n] ")
        if all_slaves_killed == 'y':
            for appName in tqdm.tqdm(apps_to_scale):
                scale_value = apps_to_scale.get(appName)
                print("scaling app: {0} to {1}.".format(appName, scale_value))
                scale(appName, scale_value)
                waitForTargetScale(appName, scale_value)


def decommissionCommand(decommissionClusterOptionsParser):
    subject = "[Babe Alert] Decommissioning " + decommissionClusterOptionsParser.hostname
    content = "Hostname: " + str(decommissionClusterOptionsParser.hostname) + "<br>" + "mesos_endpoint: " + str(decommissionClusterOptionsParser.mesos_endpoint) + "<br>" + "User: " + getpass.getuser()
    sendEmail(subject, content, getEmailTo(babeConfig), None)
    decommission(decommissionClusterOptionsParser.mesos_endpoint, decommissionClusterOptionsParser.hostname)

def waitForTargetScale(appName, targetScale):
    while True:
        r = getAppInfo(appName)
        if None == r:
            print("No app: " + appName)
            exit(1)
        data=r.json()
        app=data['app']
        instances = app['tasks']
        healthy = 0
        for instance in instances:
            if isInstanceHealthy(instance):
                healthy += 1
        if healthy == targetScale:
            print("Target scale factor reached: " + str(targetScale))
            return
        else:
            print("Current scale factor: " + str(healthy) + " Target: " + str(targetScale))
        time.sleep(3)

def restartCommand(restartOptionsParser):
    appName = restartOptionsParser.app
    grace = restartOptionsParser.grace
    lbOOR = restartOptionsParser.lboor
    rangerOOR = restartOptionsParser.rangeroor
    parallelism = restartOptionsParser.parallelism
    fabric = restartOptionsParser.isfabric
    r = getAppInfo(appName)
    if None == r:
        print("Error: No such app:" + appName)
        return
    data=r.json()
    app=data['app']
    appOwnerEmail = getAppOwnerEmail(app)
    isNodeApp = getIsNodeAppFromApp(app)
    subject = "[Babe Alert] Restarting " + str(app['id'])
    content = "App: " + str(app['id']) + "<br>" + "Endpoint: " + str(marathon) + "<br>" + "grace: "+ str(grace) +"<br>parallelism: "+str(parallelism)+"<br>User: " + getpass.getuser()
    if None == appOwnerEmail:
        content = content + "<br> Warning: No app owner registered for "+ str(app['id'])
    sendEmail(subject, content, getEmailTo(babeConfig), appOwnerEmail)

    sortInstancesByStagingTime(app)
    instances = app['tasks']
    if 0 == len(instances):
        print("There are no running instances. Use 'scale' to scale up")
        return
    targetScale=len(instances)
    if parallelism > 1:
        maxAllowedParallelism = int(targetScale/2)
        if(maxAllowedParallelism<1) :
            maxAllowedParallelism = 1
        if parallelism > maxAllowedParallelism:
            print("parallelism can not be more than " + str(maxAllowedParallelism))
            return
        if restartOptionsParser.noScaling == False:
            targetScale=len(instances) + parallelism
            scale(appName, targetScale)
            waitForTargetScale(appName, targetScale)
        for i in tqdm.tqdm(range(0, len(instances), parallelism)):
            instances_batch = instances[i:i+parallelism]
            if i + parallelism > len(instances) - parallelism and len(instances_batch) == parallelism and restartOptionsParser.noScaling == False:
                    print("suspending with scale down")
                    suspendParallel(appName, instances_batch, grace, rangerOOR, lbOOR, parallelism, True, isNodeApp, fabric)
                    targetScale = targetScale - parallelism
            else:
                suspendParallel(appName, instances_batch, grace, rangerOOR, lbOOR, parallelism, False, isNodeApp, fabric)
            waitForTargetScale(appName, targetScale)
        if restartOptionsParser.noScaling == False:
            scale(appName, targetScale)
            waitForTargetScale(appName, targetScale)
        print("App Restarted")
    else :
        if restartOptionsParser.noScaling == False:
            targetScale=len(instances) + 1
            scale(appName, targetScale)
            waitForTargetScale(appName, targetScale)
        for instance in tqdm.tqdm(instances):
            killInstance(appName, instance, grace, rangerOOR, lbOOR, False, isNodeApp, fabric)
            time.sleep(2)
            if (instances.index(instance) == len(instances) - 1):
                if restartOptionsParser.noScaling == False:
                    scale(appName, targetScale - 1)
                    waitForTargetScale(appName, targetScale - 1)
                else:
                    waitForTargetScale(appName, targetScale)
            else:
                waitForTargetScale(appName, targetScale)
            print("Instance " + instance['id'] + " replaced")
        if restartOptionsParser.noScaling == False:
            scale(appName, targetScale - 1)
            waitForTargetScale(appName, targetScale - 1)
        print("App restarted")

def infoCommand(infoOptionsParser):
    r = getAppInfo(infoOptionsParser.app)
    if None == r:
        print("Error: No such app:" + infoOptionsParser.app)
        return
    data=r.json()
    app=data['app']
    sortInstancesByStagingTime(app)
    printInfoTable([app])
    if not 'taskStats' in app or not 'totalSummary' in app['taskStats']:
        print("App is down")
    else:
        rows = []
        for instance in app['tasks']:
            loadInstance(instance, rows)
        print(tabulate(rows, headers=["Instance", "host", "Ports", "Started", "Status"], tablefmt='fancy_grid'))
        rows=[]
        for deployment in app['deployments']:
            rows.append([deployment['id']])
        if len(rows) > 0:
            print(tabulate(rows, headers=["Deployment ID"], tablefmt='fancy_grid'))


def scaleCommand(scaleOptionsParser):
    appName = scaleOptionsParser.app
    grace = scaleOptionsParser.grace
    lbOOR = scaleOptionsParser.lboor
    rangerOOR = scaleOptionsParser.rangeroor
    fabric = scaleOptionsParser.isfabric
    parallelism = scaleOptionsParser.parallelism
    r = getAppInfo(appName)
    if None == r:
        print("Error: No such app:" + appName)
        return
    data=r.json()
    app=data['app']
    sortInstancesByStagingTime(app)
    instances = app['tasks']
    instanceCount=scaleOptionsParser.instances
    currentInstances=len(instances)

    appOwnerEmail = getAppOwnerEmail(app)
    subject = "[Babe Alert] Scaling " + str(app['id'])
    content = "App: " + str(app['id']) + "<br>" + "Endpoint: " + str(marathon) + "<br>" + "currentInstances: "+str(currentInstances)+"<br>scale to: "+str(instanceCount)+"<br>grace: "+str(grace)+"<br>parallelism: "+str(parallelism)+"<br>User: " + getpass.getuser()
    if None == appOwnerEmail:
        content = content + "<br> Warning: No app owner registered for "+ str(app['id'])
    sendEmail(subject, content, getEmailTo(babeConfig), appOwnerEmail)

    isNodeApp = getIsNodeAppFromApp(app)
    if instanceCount == currentInstances:
        print("Nothing to do. Already at: " + str(currentInstances))
        return
    if parallelism > 1:
        if instanceCount > currentInstances:
           while instanceCount > currentInstances:
               targetScale = instanceCount + parallelism
               if targetScale > instanceCount:
                   targetScale = instanceCount
               scale(appName, targetScale)
               waitForTargetScale(appName, targetScale)
               currentInstances = targetScale
        else:
            numberOfInstancesToKill = currentInstances - instanceCount
            instancesToSuspend = instances[0:numberOfInstancesToKill]
            suspendParallel(appName, instancesToSuspend, grace, rangerOOR, lbOOR, parallelism, True, isNodeApp)
            waitForTargetScale(appName, instanceCount)
    else:
        for instance in instances:
            if instanceCount >= currentInstances:
                break
            killInstance(appName, instance, grace, rangerOOR, lbOOR, True, isNodeApp, fabric)
            time.sleep(2)
            currentInstances = currentInstances - 1
            print("Instance " + instance['id'] + " stop requested")
        scale(appName, instanceCount)
        waitForTargetScale(appName, instanceCount)

def suspendCommand(suspendOptionsParser):
    appName = suspendOptionsParser.app
    grace = suspendOptionsParser.grace
    lbOOR = suspendOptionsParser.lboor
    rangerOOR = suspendOptionsParser.rangeroor
    destroy = suspendOptionsParser.destroy
    parallelism = suspendOptionsParser.parallelism
    fabric = suspendOptionsParser.isfabric
    r = getAppInfo(appName)
    if None == r:
        print("Error: No such app:" + appName)
        return
    data=r.json()
    app=data['app']
    sortInstancesByStagingTime(app)
    instances = app['tasks']
    currentInstances = len(instances)
    isNodeApp = getIsNodeAppFromApp(app)

    keyboard_response = raw_input("Commencing suspend operation.... Are you sure [y/n]? ")
    if keyboard_response == 'y':
        appOwnerEmail = getAppOwnerEmail(app)
        subject = "[Babe Alert] Suspending " + str(app['id'])
        content = "App: " + str(app['id']) + "<br>" + "Endpoint: " + str(marathon) + "<br>" + "grace: " + str(grace) + "<br>parallelism: " + str(parallelism) + "<br>User: " + getpass.getuser()
        if None == appOwnerEmail:
            content = content + "<br> Warning: No app owner registered for "+ str(app['id'])
        sendEmail(subject, content, getEmailTo(babeConfig), appOwnerEmail)

        if parallelism > 1:
            suspendParallel(appName, instances, grace, rangerOOR, lbOOR, parallelism, True, isNodeApp, fabric)
            waitForTargetScale(appName, 0)
        else:
            for instance in tqdm.tqdm(instances):
                killInstance(appName, instance, grace, rangerOOR, lbOOR, True, isNodeApp, fabric)
                time.sleep(2)
                currentInstances = currentInstances - 1
            waitForTargetScale(appName, 0)
        if destroy:
            destroyApp(appName, force=True)

def killSingleAppInstance(killSingleAppConfig):
    appName = killSingleAppConfig.app
    instanceId = killSingleAppConfig.instance
    grace = killSingleAppConfig.grace
    lbOOR = killSingleAppConfig.lboor
    rangerOOR = killSingleAppConfig.rangeroor
    fabric = killSingleAppConfig.isfabric
    r = getAppInfo(appName)
    if None == r:
        print("Error: No such app:" + appName)
        return
    data=r.json()
    app=data['app']
    instances = app['tasks']
    candidateInstance = None
    isNodeApp = getIsNodeAppFromApp(app)

    appOwnerEmail = getAppOwnerEmail(app)
    subject = "[Babe Alert] Killing one instance of " + str(app['id'])
    content = "App: " + str(app['id']) + "<br>" + "Endpoint: " + str(marathon) + "<br>" + "instanceId: " + str(instanceId) + "<br>grace: " + str(grace) + "<br>User: " + getpass.getuser()
    if None == appOwnerEmail:
        content = content + "<br> Warning: No app owner registered for "+ str(app['id'])
    sendEmail(subject, content, getEmailTo(babeConfig), appOwnerEmail)

    for instance in instances:
        if instance['id'] == instanceId:
            candidateInstance = instance
            break
    if candidateInstance == None:
        print("Error: Invalid instance ID: " + instanceId)
    currentInstances=len(instances)
    killInstance(appName, instance, grace, rangerOOR, lbOOR, True, isNodeApp, fabric)
    waitForTargetScale(appName, currentInstances - 1)

def getUserPassword():
    password = getpass.getpass(prompt='Password: ', stream=None)
    return password

def sortInstancesByStagingTime(app):
    app['tasks'].sort(key=lambda x: int(time.mktime(datetime.strptime(x['stagedAt'], '%Y-%m-%dT%H:%M:%S.%fZ').timetuple()) * 1000))

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Marathon apps manager. Named after main character in Marathon Man.')
    parser.add_argument('-e', '--endpoint', help='Marathon host:port', default="localhost:8080", required=True)
    parser.add_argument('-p', '--protocol', help='Protocol for Marathon endpoint', choices=['http','https'], default="http")
    parser.add_argument('-k', '--ssl-insecure', help='Skip SSL Check', dest='sslVerify', action='store_false')
    parser.add_argument('-U', '--user', help='HTTP Basic authentication username ( password will be asked via prompt )', default="", required=False)
    parser.add_argument('-C', '--configuration', help='Babe configuration file path', default=defaultConfigPath, required=False)
    parser.add_argument('-t', '--requests-timeout', help='Timeout value for requests', type=int, dest='requestsTimeout', default=5)
    parser.add_argument('-ap', '--admin-port', help='Admin port index', type=int, dest='adminPort', default=1)

    subparsers = parser.add_subparsers(help='Available operations')

    #List
    listOptionsParser = subparsers.add_parser('list', help='List running apps')
    listOptionsParser.add_argument('-u', '--up', help='Show only apps that are alive', action='store_true')
    listOptionsParser.add_argument('-d', '--down', help='Show only apps that are dead', action='store_true')
    listOptionsParser.add_argument('-s', '--search', help='Show only apps that match the search term', default=None)
    listOptionsParser.set_defaults(func=listCommand)

    #Info
    infoOptionsParser = subparsers.add_parser('info', help='Info about a running app')
    infoOptionsParser.add_argument('app', help='App name')
    infoOptionsParser.set_defaults(func=infoCommand)

    #Deploy
    deployOptionsParser = subparsers.add_parser('deploy', help='Deploy an app')
    deployOptionsParser.add_argument('-c' , '--config', help='Deployment json descriptor', required=True)
    deployOptionsParser.set_defaults(func=deployCommand)

    #Restart
    restartOptionsParser = subparsers.add_parser('restart', help='Restart an app')
    restartOptionsParser.add_argument('app', help='App name')
    restartOptionsParser.add_argument('-g', '--grace', help='Grace period to sleep for before killing the process', type=int, default=30)
    restartOptionsParser.add_argument('-n', '--no-scaling', help="Don't scale up the app before killing the processs", dest='noScaling', action='store_true')
    restartOptionsParser.add_argument('-l', '--lb-oor', help='Whether to take it OOR in load balancer as well', dest='lboor', action='store_true')
    restartOptionsParser.add_argument('-r', '--ranger-oor', help='Whether to take it OOR in ranger as well', dest='rangeroor', action='store_false')
    restartOptionsParser.add_argument('-pl', '--parallelism', help='number of parallel process to execute this command', type=int, default=1)
    restartOptionsParser.add_argument('-f', '--fabric', help='Whether it is a Fabric processor', dest='isfabric', action='store_true')
    restartOptionsParser.set_defaults(func=restartCommand)

    #Scale
    scaleOptionsParser = subparsers.add_parser('scale', help='Scale an app')
    scaleOptionsParser.add_argument('app', help='App name')
    scaleOptionsParser.add_argument('-n', '--instances', help='Number of instances required. This number is absolute.', type=int, required=True)
    scaleOptionsParser.add_argument('-g', '--grace', help='Grace period to sleep for before killing the process', type=int, default=35)
    scaleOptionsParser.add_argument('-l', '--lb-oor', help='Whether to take it OOR in load balancer as well', dest='lboor', action='store_true')
    scaleOptionsParser.add_argument('-r', '--ranger-oor', help='Whether to take it OOR in ranger as well', dest='rangeroor', action='store_false')
    scaleOptionsParser.add_argument('-f', '--fabric', help='Whether it is a Fabric processor', dest='isfabric', action='store_true')
    scaleOptionsParser.add_argument('-pl', '--parallelism', help='number of parallel process to execute this command', type=int, default=1)
    scaleOptionsParser.set_defaults(func=scaleCommand)

    #Suspend
    suspendOptionsParser = subparsers.add_parser('suspend', help='Suspend an app (equivalent to scale=0)')
    suspendOptionsParser.add_argument('app', help='App name')
    suspendOptionsParser.add_argument('-g', '--grace', help='Grace period to sleep for before killing the process', type=int, default=35)
    suspendOptionsParser.add_argument('-l', '--lb-oor', help='Whether to take it OOR in load balancer as well', dest='lboor', action='store_true')
    suspendOptionsParser.add_argument('-r', '--ranger-oor', help='Whether to take it OOR in ranger as well', dest='rangeroor', action='store_false')
    suspendOptionsParser.add_argument('-d', '--destroy', help='If this flag is set, then the app will be destroyed after suspension if it has zero instances running', dest='destroy', action='store_true', default=False)
    suspendOptionsParser.add_argument('-pl', '--parallelism', help='number of parallel process to execute this command', type=int, default=1)
    suspendOptionsParser.add_argument('-f', '--fabric', help='Whether it is a Fabric processor', dest='isfabric', action='store_true')
    suspendOptionsParser.set_defaults(func=suspendCommand)

    #Kill Instance
    killInstanceOptionsParser = subparsers.add_parser('kill', help='Kill an app instance')
    killInstanceOptionsParser.add_argument('app', help='App name')
    killInstanceOptionsParser.add_argument('-i', '--instance', help='Instance ID to be killed', required=True)
    killInstanceOptionsParser.add_argument('-g', '--grace', help='Grace period to sleep for before killing the process', type=int, default=35)
    killInstanceOptionsParser.add_argument('-l', '--lb-oor', help='Whether to take it OOR in load balancer as well', dest='lboor', action='store_true')
    killInstanceOptionsParser.add_argument('-r', '--ranger-oor', help='Whether to skip taking instance OOR in ranger', dest='rangeroor', action='store_false')
    killInstanceOptionsParser.add_argument('-f', '--fabric', help='Whether it is a Fabric processor', dest='isfabric', action='store_true')
    killInstanceOptionsParser.set_defaults(func=killSingleAppInstance)

    #Destroy App
    destroyAppOptionsParser = subparsers.add_parser('destroy', help='Destroy an app instance')
    destroyAppOptionsParser.add_argument('app', help='App name')
    destroyAppOptionsParser.set_defaults(func=destroyCommand)

    #Decommission Cluster
    decommissionClusterOptionsParser = subparsers.add_parser('decommission', help='Decommission a Mesos slave')
    decommissionClusterOptionsParser.add_argument('-m', '--mesos-endpoint', help='Mesos master host:port', dest='mesos_endpoint')
    decommissionClusterOptionsParser.add_argument('-n', '--hostname', help='Hostname of Mesos slave that needs to be decommissioned', default='localhost', required=True)
    decommissionClusterOptionsParser.set_defaults(func=decommissionCommand)

    parsed=parser.parse_args()
    babeConfig = readConfig(parsed.configuration)
    disableEmail = (None == babeConfig)
    marathon = parsed.endpoint
    useAuth = len(parsed.user) > 0
    if useAuth == True:
        password = getUserPassword()
        httpBasicCreds = HTTPBasicAuth(parsed.user, password)
    httpsVerify = parsed.sslVerify
    protocol = parsed.protocol
    requestsTimeout = parsed.requestsTimeout
    adminPort = parsed.adminPort
    parsed.func(parsed)
